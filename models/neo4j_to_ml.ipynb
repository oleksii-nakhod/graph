{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "old_level = logger.level\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "if os.path.basename(os.getcwd()) != 'graph':\n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Config\n",
    "\n",
    "data_dir = 'data/transaction'\n",
    "base_url = Config.BASE_URL\n",
    "\n",
    "node_url = f\"{base_url}/api/nodes\"\n",
    "edge_url = f\"{base_url}/api/edges\"\n",
    "batch_size = 10_000\n",
    "transactions_raw_file = f'{data_dir}/transactions_raw.pkl'\n",
    "transactions_file = f'{data_dir}/transactions.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import EllipticBitcoinDataset\n",
    "\n",
    "# dataset_lib = EllipticBitcoinDataset(root=f'{data_dir}/EllipticBitcoin', transform=None)\n",
    "# data_lib = dataset_lib[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.helpers import fetch_and_process_graph_data\n",
    "\n",
    "# nodes, edges = fetch_and_process_graph_data(node_url, edge_url, transactions_raw_file, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.helpers import create_data_object, save_data\n",
    "\n",
    "# data = create_data_object(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# labels = data.y.cpu()\n",
    "# class_0_1_indices = torch.where((labels == 0) | (labels == 1))[0]\n",
    "# num_samples = len(class_0_1_indices)\n",
    "# train_end, val_end = int(0.7 * num_samples), int(0.85 * num_samples)\n",
    "\n",
    "# train_indices, val_indices, test_indices = class_0_1_indices.split([train_end, val_end - train_end, num_samples - val_end])\n",
    "\n",
    "# masks = torch.zeros((3, len(data.y)), dtype=torch.bool, device=data.y.device)\n",
    "# masks[0, train_indices] = True\n",
    "# masks[1, val_indices] = True\n",
    "# masks[2, test_indices] = True\n",
    "\n",
    "# data.train_mask, data.val_mask, data.test_mask = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_data(data, transactions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.helpers import load_data\n",
    "\n",
    "data = load_data(transactions_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.transaction import TransactionClassifierGCN\n",
    "\n",
    "# transaction_classifier_gcn = TransactionClassifierGCN()\n",
    "# transaction_classifier_gcn.fit(data, epochs=1000)\n",
    "# transaction_classifier_gcn.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.helpers import save_model\n",
    "# save_model(transaction_classifier_gcn.state_dict(), 'models/transaction_classifier_gcn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torcheval.metrics.functional import multiclass_f1_score, mean_squared_error\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super(GNN, self).__init__()\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.optimizer = None\n",
    "        self.loss_fn = None\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index) if 'Conv' in layer.__class__.__name__ else layer(x)\n",
    "        return x\n",
    "\n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def fit(self, data, epochs=1000, patience=10):\n",
    "        history = {'train_loss': [], 'val_loss': [], 'train_metric': [], 'val_metric': []}\n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self(data)\n",
    "            train_loss, train_metric = self._compute_loss_and_metric(out, data, 'train')\n",
    "            val_loss, val_metric = self._compute_loss_and_metric(out, data, 'val')\n",
    "            history['train_loss'].append(train_loss.item())\n",
    "            history['val_loss'].append(val_loss.item())\n",
    "            history['train_metric'].append(train_metric.item())\n",
    "            history['val_metric'].append(val_metric.item())\n",
    "            train_loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Training Loss: {train_loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch}\")\n",
    "                    break\n",
    "        return history\n",
    "    \n",
    "    def predict(self, data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            return self(data)\n",
    "\n",
    "    def evaluate(self, data, mode='val'):\n",
    "        y_true, y_pred = self._get_true_and_predicted(data, mode)\n",
    "        return self.calculate_metrics(y_true, y_pred)\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def load_for_inference(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()\n",
    "\n",
    "    def _compute_loss_and_metric(self, out, data, mode):\n",
    "        mask = getattr(data, f\"{mode}_mask\")\n",
    "        y_true = data.y[mask]\n",
    "        y_pred = out[mask]\n",
    "        loss = self.loss_fn(y_pred, y_true)\n",
    "        metric = self.calculate_metrics(y_true, torch.argmax(y_pred, dim=1))\n",
    "        return loss, metric\n",
    "    \n",
    "    def _get_true_and_predicted(self, data, mode):\n",
    "        mask = getattr(data, f\"{mode}_mask\")\n",
    "        y_true = data.y[mask]\n",
    "        y_pred = self.predict(data)[mask]\n",
    "        return y_true, y_pred\n",
    "\n",
    "\n",
    "class GNNClassifier(GNN):\n",
    "    def __init__(self, layers):\n",
    "        super(GNNClassifier, self).__init__(layers)\n",
    "    \n",
    "    def predict(self, data):\n",
    "        out = super().predict(data)\n",
    "        return torch.argmax(out, dim=1)\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        num_classes = y_true.max().item() + 1\n",
    "        return multiclass_f1_score(y_true, y_pred, num_classes=num_classes, average='macro')\n",
    "\n",
    "\n",
    "class GNNRegressor(GNN):\n",
    "    def __init__(self, layers):\n",
    "        super(GNNRegressor, self).__init__(layers)\n",
    "    \n",
    "    def calculate_metrics(self, y_true, y_pred):\n",
    "        return mean_squared_error(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_classes(data, mask=None):\n",
    "    unique_classes, counts = torch.unique(data.y[mask], return_counts=True)\n",
    "    for cls, count in zip(unique_classes.tolist(), counts.tolist()):\n",
    "        print(f\"Class {cls}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def objective(trial, data, layer):\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 16, 64)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.0, 0.5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
    "\n",
    "    layers = []\n",
    "    in_channels = data.num_features\n",
    "    out_channels = data.y[data.train_mask].max().item() + 1\n",
    "    class_counts = Counter(data.y[data.train_mask].cpu().numpy())\n",
    "    total = sum(class_counts.values())\n",
    "    class_weights = {c: total / count for c, count in class_counts.items()}\n",
    "\n",
    "    class_weights = torch.tensor([class_weights[c] for c in sorted(class_weights)], device=data.y.device)\n",
    "    \n",
    "    for _ in range(num_layers):\n",
    "        layers.append(layer(in_channels, hidden_channels))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        layers.append(torch.nn.Dropout(dropout_rate))\n",
    "        in_channels = hidden_channels\n",
    "    layers.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "    model = GNNClassifier(layers).to(data.y.device)\n",
    "    model.compile(\n",
    "        optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate),\n",
    "        loss_fn=torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    )\n",
    "\n",
    "    model_history = model.fit(data, epochs=1000)\n",
    "    trial.set_user_attr('history', model_history)\n",
    "    trial.set_user_attr('model', model)\n",
    "    return model.evaluate(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def conduct_study(data, layer_types, n_trials=10):\n",
    "    study_results = {}\n",
    "\n",
    "    for layer in layer_types:\n",
    "        layer_name = layer.__name__\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: objective(trial, data, layer), n_trials=n_trials)\n",
    "\n",
    "        best_trial = study.best_trial\n",
    "        study_results[layer_name] = {\n",
    "            'trial_values': [t.value for t in study.trials],\n",
    "            'best_model': best_trial.user_attrs['model'],\n",
    "            'best_model_history': best_trial.user_attrs['history'],\n",
    "        }\n",
    "\n",
    "    return study_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATConv, GCNConv, TransformerConv\n",
    "\n",
    "layer_types = [torch.nn.Linear, GCNConv, GATConv, TransformerConv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torcheval.metrics.functional import multiclass_accuracy, multiclass_precision, multiclass_recall, multiclass_confusion_matrix, multiclass_f1_score\n",
    "\n",
    "def visualize_study_results(study_results, data):\n",
    "    layer_metrics = {layer: results['trial_values'] for layer, results in study_results.items()}\n",
    "\n",
    "    best_layer = None\n",
    "    best_trial_value = float('-inf')\n",
    "    for layer, results in study_results.items():\n",
    "        max_trial_value = max(results['trial_values'])\n",
    "        if max_trial_value > best_trial_value:\n",
    "            best_trial_value = max_trial_value\n",
    "            best_layer = layer\n",
    "            best_model = results['best_model']\n",
    "            best_model_history = results['best_model_history']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.boxplot([\n",
    "        values\n",
    "        for values in layer_metrics.values()\n",
    "    ], labels=layer_metrics.keys())\n",
    "    plt.title('Performance Comparison')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(best_model_history['train_loss'], label='Training Loss')\n",
    "    plt.plot(best_model_history['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss History for {best_layer}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(best_model_history['train_metric'], label='Training Metric')\n",
    "    plt.plot(best_model_history['val_metric'], label='Validation Metric')\n",
    "    plt.title(f'Metric History for {best_layer}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    y_true = data.y[data.val_mask]\n",
    "    num_classes = y_true.max().item() + 1\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_pred = best_model.predict(data)[data.val_mask]\n",
    "        confusion_mat = multiclass_confusion_matrix(y_pred, y_true, num_classes)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(confusion_mat.cpu().numpy(), interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = range(data.y.max().item() + 1)\n",
    "    plt.xticks(tick_marks)\n",
    "    plt.yticks(tick_marks)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "    metrics_data = []\n",
    "    for layer, results in study_results.items():\n",
    "        best_model = results['best_model']\n",
    "        y_pred = best_model.predict(data)[data.val_mask]\n",
    "        accuracy = multiclass_accuracy(y_pred, y_true, num_classes=num_classes, average='macro').item()\n",
    "        precision = multiclass_precision(y_pred, y_true, num_classes=num_classes, average='macro').item()\n",
    "        recall = multiclass_recall(y_pred, y_true, num_classes=num_classes, average='macro').item()\n",
    "        f1 = multiclass_f1_score(y_pred, y_true, num_classes=num_classes, average='macro').item()\n",
    "        metrics_data.append({\n",
    "            'Layer Type': layer,\n",
    "            'Accuracy': accuracy,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-Score': f1\n",
    "        })\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def create_val_test_masks(train_mask, val_test_ratio=0.5):\n",
    "  non_train_indices = torch.where(~train_mask)[0]\n",
    "\n",
    "  num_val = int(val_test_ratio * len(non_train_indices))\n",
    "\n",
    "  shuffled_indices = torch.randperm(len(non_train_indices))\n",
    "\n",
    "  val_indices = non_train_indices[shuffled_indices[:num_val]]\n",
    "  test_indices = non_train_indices[shuffled_indices[num_val:]]\n",
    "\n",
    "  val_mask = torch.zeros_like(train_mask, dtype=torch.bool)\n",
    "  test_mask = torch.zeros_like(train_mask, dtype=torch.bool)\n",
    "  val_mask[val_indices] = True\n",
    "  test_mask[test_indices] = True\n",
    "\n",
    "  return val_mask, test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_amazon = Amazon(root=f'{data_dir}/Amazon', name='Computers')[0].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_masks(data, train_ratio=0.7, val_ratio=0.15, random_state=None):\n",
    "    num_samples = len(data.y)\n",
    "    labels = data.y.cpu().numpy()\n",
    "    test_ratio = 1 - train_ratio - val_ratio\n",
    "    \n",
    "    train_indices, tmp_indices = train_test_split(\n",
    "        torch.arange(num_samples), train_size=train_ratio, stratify=labels, random_state=random_state\n",
    "    )\n",
    "    val_indices, test_indices = train_test_split(\n",
    "        tmp_indices, test_size=test_ratio/(test_ratio+val_ratio), stratify=labels[tmp_indices], random_state=random_state\n",
    "    )\n",
    "\n",
    "    masks = torch.zeros((3, num_samples), dtype=torch.bool)\n",
    "    masks[0, train_indices] = True\n",
    "    masks[1, val_indices] = True\n",
    "    masks[2, test_indices] = True\n",
    "\n",
    "    data.train_mask, data.val_mask, data.test_mask = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_masks(data_amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752], train_mask=[13752], val_mask=[13752], test_mask=[13752])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_amazon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study_amazon = conduct_study(data_amazon, layer_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_study_results(study_amazon, data_amazon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import WordNet18RR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18RR/original/train.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18RR/original/valid.txt\n",
      "Downloading https://raw.githubusercontent.com/villmow/datasets_knowledge_embedding/master/WN18RR/original/test.txt\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_wordnet = WordNet18RR(root=f'{data_dir}/WordNet18RR')[0].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 93003], edge_type=[93003], train_mask=[93003], val_mask=[93003], test_mask=[93003], num_nodes=40943)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(86835, device='cuda:0'),\n",
       " tensor(3034, device='cuda:0'),\n",
       " tensor(3134, device='cuda:0'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wordnet.train_mask.count_nonzero(), data_wordnet.val_mask.count_nonzero(), data_wordnet.test_mask.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     1,  ..., 40933, 40934, 40935],\n",
       "        [10211, 25525,  3891,  ...,  8943,  8648,  6809]], device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_wordnet.edge_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
