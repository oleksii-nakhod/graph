{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import EllipticBitcoinDataset\n",
    "from sklearn.metrics import classification_report\n",
    "import requests\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_lib = EllipticBitcoinDataset(root='EllipticBitcoin', transform=None)\n",
    "data_lib = dataset_lib[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://localhost:5004'\n",
    "node_url = f\"{base_url}/api/nodes\"\n",
    "edge_url = f\"{base_url}/api/edges\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "batch_size = 10_000\n",
    "cache_file = 'data_cache.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, headers, batch_size, page):\n",
    "    params = {\"page_size\": batch_size, \"page\": page}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def process_nodes(existing_nodes, new_nodes):\n",
    "    node_id_map = {node['id']: idx for idx, node in enumerate(existing_nodes)}\n",
    "    start_idx = len(existing_nodes)\n",
    "    \n",
    "    for node in new_nodes:\n",
    "        if node['id'] not in node_id_map:\n",
    "            node_id_map[node['id']] = start_idx\n",
    "            existing_nodes.append(node)\n",
    "            start_idx += 1\n",
    "\n",
    "def process_edges(existing_edges, new_edges, existing_nodes):\n",
    "    node_id_map = {node['id']: idx for idx, node in enumerate(existing_nodes)}\n",
    "\n",
    "    for edge in new_edges:\n",
    "        if edge['src'] in node_id_map and edge['dst'] in node_id_map:\n",
    "            existing_edges.append(edge)\n",
    "\n",
    "def save_cache(nodes, edges, node_page, edge_page):\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump((nodes, edges, node_page, edge_page), f)\n",
    "\n",
    "def load_cache():\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None, None, 1, 1\n",
    "\n",
    "def fetch_and_process_data():\n",
    "    existing_nodes, existing_edges, node_page, edge_page = load_cache()\n",
    "\n",
    "    if existing_nodes is None:\n",
    "        existing_nodes = []\n",
    "    if existing_edges is None:\n",
    "        existing_edges = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            node_data = fetch_data(node_url, headers, batch_size, node_page)\n",
    "            new_nodes = node_data['results']\n",
    "            \n",
    "            if not new_nodes:\n",
    "                break\n",
    "            \n",
    "            process_nodes(existing_nodes, new_nodes)\n",
    "            start_idx = (node_page - 1) * batch_size\n",
    "            end_idx = start_idx + len(new_nodes) - 1\n",
    "            print(f\"Nodes {start_idx}-{end_idx} retrieved.\")\n",
    "            node_page += 1\n",
    "            save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "\n",
    "        while True:\n",
    "            edge_data = fetch_data(edge_url, headers, batch_size, edge_page)\n",
    "            new_edges = edge_data['results']\n",
    "            \n",
    "            if not new_edges:\n",
    "                break\n",
    "            \n",
    "            process_edges(existing_edges, new_edges, existing_nodes)\n",
    "            start_idx = (edge_page - 1) * batch_size\n",
    "            end_idx = start_idx + len(new_edges) - 1\n",
    "            print(f\"Edges {start_idx}-{end_idx} retrieved.\")\n",
    "            edge_page += 1\n",
    "            save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "        raise\n",
    "\n",
    "    return existing_nodes, existing_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = fetch_and_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object(nodes, edges):\n",
    "    node_features = []\n",
    "    node_labels = []\n",
    "    node_id_map = {}\n",
    "\n",
    "    for idx, node in enumerate(nodes):\n",
    "        node_id_map[node['id']] = idx\n",
    "        node_features.append(node['x'])\n",
    "        node_labels.append(node['y'])\n",
    "\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    node_labels = torch.tensor(node_labels, dtype=torch.long)\n",
    "\n",
    "    edge_index = []\n",
    "    for edge in edges:\n",
    "        src = node_id_map[edge['src']]\n",
    "        dst = node_id_map[edge['dst']]\n",
    "        edge_index.append([src, dst])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False,  ..., False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lib.train_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_object(nodes, edges)\n",
    "data.train_mask = data_lib.train_mask.clone()\n",
    "data.test_mask = data_lib.test_mask.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, class_weights):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        self.class_weights = class_weights\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(self.class_weights)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def fit(self, data):\n",
    "        self.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        out = self(data)\n",
    "        loss = self.loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def predict(self, data):\n",
    "        self.eval()\n",
    "        out = self(data)\n",
    "        _, pred = out.max(dim=1)\n",
    "        correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
    "        acc = correct / data.test_mask.sum().item()\n",
    "        return acc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "data = data_lib\n",
    "\n",
    "model = GCN(in_channels=data.x.shape[1], hidden_channels=100, out_channels=2, class_weights=torch.tensor([0.3, 0.7])).to(device)\n",
    "\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13144)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_true==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[203769, 165], edge_index=[2, 234355], y=[203769], train_mask=[203769], test_mask=[203769])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute x is different.\n",
      "Differences found at indices: (tensor([     0,      0,      0,  ..., 203768, 203768, 203768]), tensor([  0,   1,   2,  ..., 162, 163, 164]))\n",
      "data.x values at differences: tensor([-0.1729, -0.1515,  1.0186,  ..., -0.0975, -0.1206, -0.1198])\n",
      "data_lib.x values at differences: tensor([-0.1715, -0.1847, -1.2014,  ..., -0.1406,  1.5197,  1.5214])\n",
      "Attribute edge_index is different.\n",
      "Differences found at indices: (tensor([0, 0, 0,  ..., 1, 1, 1]), tensor([     0,      1,      2,  ..., 234352, 234353, 234354]))\n",
      "data.edge_index values at differences: tensor([ 11078,    941,   1037,  ..., 202619, 202184, 203242])\n",
      "data_lib.edge_index values at differences: tensor([     0,      2,      4,  ..., 202042, 201368, 201756])\n",
      "Attribute y is different.\n",
      "Differences found at indices: (tensor([     1,      3,      6,  ..., 203762, 203766, 203768]),)\n",
      "data.y values at differences: tensor([0, 2, 0,  ..., 0, 2, 0])\n",
      "data_lib.y values at differences: tensor([2, 0, 2,  ..., 2, 1, 2])\n",
      "Attribute train_mask is the same.\n",
      "Attribute test_mask is the same.\n",
      "Comparison complete.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compare_data(data, data_lib):\n",
    "    attributes = ['x', 'edge_index', 'y', 'train_mask', 'test_mask']\n",
    "    \n",
    "    for attr in attributes:\n",
    "        data_attr = getattr(data, attr, None)\n",
    "        data_lib_attr = getattr(data_lib, attr, None)\n",
    "        \n",
    "        if data_attr is None or data_lib_attr is None:\n",
    "            print(f\"Attribute {attr} is missing in one of the objects.\")\n",
    "            continue\n",
    "        \n",
    "        if not torch.equal(data_attr, data_lib_attr):\n",
    "            print(f\"Attribute {attr} is different.\")\n",
    "            \n",
    "            if data_attr.shape != data_lib_attr.shape:\n",
    "                print(f\"Shapes are different: {data_attr.shape} vs {data_lib_attr.shape}\")\n",
    "            else:\n",
    "                # Compare the values and print where they differ\n",
    "                differences = (data_attr != data_lib_attr).nonzero(as_tuple=True)\n",
    "                if differences[0].numel() == 0:\n",
    "                    print(f\"Values are the same but the tensors are not equal due to dtype or device mismatch.\")\n",
    "                else:\n",
    "                    print(f\"Differences found at indices: {differences}\")\n",
    "                    print(f\"data.{attr} values at differences: {data_attr[differences]}\")\n",
    "                    print(f\"data_lib.{attr} values at differences: {data_lib_attr[differences]}\")\n",
    "        else:\n",
    "            print(f\"Attribute {attr} is the same.\")\n",
    "    \n",
    "    print(\"Comparison complete.\")\n",
    "\n",
    "# Example usage\n",
    "compare_data(data, data_lib)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1715, -0.1847, -1.2014,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        [-0.1715, -0.1847, -1.2014,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        [-0.1721, -0.1847, -1.2014,  ..., -0.1837, -0.1206, -0.1198],\n",
       "        ...,\n",
       "        [-0.1720, -0.0782,  1.0186,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        [-0.1728, -0.1766,  1.0186,  ..., -0.1406,  1.5197,  1.5214],\n",
       "        [-0.0120, -0.1323,  0.4636,  ..., -0.1406,  1.5197,  1.5214]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lib.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 2, 2,  ..., 1, 2, 2])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lib.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1729, -0.1515,  1.0186,  ...,  0.0748, -0.1206, -0.1198],\n",
       "        [-0.1728, -0.0511, -0.0914,  ..., -0.1406,  1.5197,  1.5214],\n",
       "        [-0.1729, -0.1311,  1.0186,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        ...,\n",
       "        [-0.1720, -0.1847, -1.2014,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        [-0.1730, -0.1780,  1.0186,  ..., -0.0975, -0.1206, -0.1198],\n",
       "        [ 0.5888, -0.2106, -1.7564,  ..., -0.0975, -0.1206, -0.1198]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 2,  ..., 2, 2, 0])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first row of data matches row 200788 in data_lib.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Function to find the first matching row index\n",
    "def find_first_matching_row(data, data_lib):\n",
    "    first_row = data.x[0]\n",
    "    all_rows = data_lib.x\n",
    "    \n",
    "    # Compare the first row of data with all rows of data_lib\n",
    "    differences = torch.sum(all_rows != first_row, dim=1)\n",
    "    \n",
    "    # Find the index of the first row that matches exactly (all differences should be 0)\n",
    "    matching_index = torch.where(differences == 0)[0]\n",
    "    \n",
    "    if len(matching_index) > 0:\n",
    "        return matching_index[0].item()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "matching_index = find_first_matching_row(data, data_lib)\n",
    "if matching_index is not None:\n",
    "    print(f\"The first row of data matches row {matching_index} in data_lib.\")\n",
    "else:\n",
    "    print(\"No matching row found in data_lib.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100, Loss: 0.2482, Test Accuracy: 0.8139\n",
      "Epoch: 200, Loss: 0.2036, Test Accuracy: 0.9005\n",
      "Epoch: 300, Loss: 0.1827, Test Accuracy: 0.9401\n",
      "Epoch: 400, Loss: 0.1671, Test Accuracy: 0.9469\n",
      "Epoch: 500, Loss: 0.1557, Test Accuracy: 0.9484\n",
      "Epoch: 600, Loss: 0.1455, Test Accuracy: 0.9498\n",
      "Epoch: 700, Loss: 0.1405, Test Accuracy: 0.9507\n",
      "Epoch: 800, Loss: 0.1324, Test Accuracy: 0.9505\n",
      "Epoch: 900, Loss: 0.1297, Test Accuracy: 0.9512\n",
      "Epoch: 1000, Loss: 0.1251, Test Accuracy: 0.9511\n",
      "Test Accuracy: 0.9511\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       licit       0.96      0.99      0.97     15587\n",
      "     illicit       0.71      0.42      0.53      1083\n",
      "\n",
      "    accuracy                           0.95     16670\n",
      "   macro avg       0.83      0.71      0.75     16670\n",
      "weighted avg       0.94      0.95      0.95     16670\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 1001):\n",
    "    loss = model.fit(data)\n",
    "    if epoch % 100 == 0:\n",
    "        acc, _ = model.predict(data)\n",
    "        print(f'Epoch: {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n",
    "\n",
    "acc, pred = model.predict(data)\n",
    "print(f'Test Accuracy: {acc:.4f}')\n",
    "\n",
    "y_true = data.y[data.test_mask].cpu()\n",
    "y_pred = pred[data.test_mask].cpu()\n",
    "print(classification_report(y_true, y_pred, target_names=['licit', 'illicit']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
