{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.datasets import EllipticBitcoinDataset\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "from sklearn.metrics import classification_report\n",
    "import requests\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "dataset_lib = EllipticBitcoinDataset(root='EllipticBitcoin', transform=None)\n",
    "data_lib = dataset_lib[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://localhost:5004'\n",
    "node_url = f\"{base_url}/api/nodes\"\n",
    "edge_url = f\"{base_url}/api/edges\"\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "batch_size = 10_000\n",
    "cache_file = 'data_cache.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url, headers, batch_size, page):\n",
    "    params = {\"page_size\": batch_size, \"page\": page}\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "    response.raise_for_status()\n",
    "    return response.json()\n",
    "\n",
    "def process_nodes(existing_nodes, new_nodes):\n",
    "    node_id_map = {node['id']: idx for idx, node in enumerate(existing_nodes)}\n",
    "    start_idx = len(existing_nodes)\n",
    "    \n",
    "    for node in new_nodes:\n",
    "        if node['id'] not in node_id_map:\n",
    "            node_id_map[node['id']] = start_idx\n",
    "            existing_nodes.append(node)\n",
    "            start_idx += 1\n",
    "\n",
    "def process_edges(existing_edges, new_edges, existing_nodes):\n",
    "    node_id_map = {node['id']: idx for idx, node in enumerate(existing_nodes)}\n",
    "\n",
    "    for edge in new_edges:\n",
    "        if edge['src'] in node_id_map and edge['dst'] in node_id_map:\n",
    "            existing_edges.append(edge)\n",
    "\n",
    "def save_cache(nodes, edges, node_page, edge_page):\n",
    "    with open(cache_file, 'wb') as f:\n",
    "        pickle.dump((nodes, edges, node_page, edge_page), f)\n",
    "\n",
    "def load_cache():\n",
    "    if os.path.exists(cache_file):\n",
    "        with open(cache_file, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    return None, None, 1, 1\n",
    "\n",
    "def fetch_and_process_data():\n",
    "    existing_nodes, existing_edges, node_page, edge_page = load_cache()\n",
    "\n",
    "    if existing_nodes is None:\n",
    "        existing_nodes = []\n",
    "    if existing_edges is None:\n",
    "        existing_edges = []\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            node_data = fetch_data(node_url, headers, batch_size, node_page)\n",
    "            new_nodes = node_data['results']\n",
    "            \n",
    "            if not new_nodes:\n",
    "                break\n",
    "            \n",
    "            process_nodes(existing_nodes, new_nodes)\n",
    "            start_idx = (node_page - 1) * batch_size\n",
    "            end_idx = start_idx + len(new_nodes) - 1\n",
    "            print(f\"Nodes {start_idx}-{end_idx} retrieved.\")\n",
    "            node_page += 1\n",
    "            save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "\n",
    "        while True:\n",
    "            edge_data = fetch_data(edge_url, headers, batch_size, edge_page)\n",
    "            new_edges = edge_data['results']\n",
    "            \n",
    "            if not new_edges:\n",
    "                break\n",
    "            \n",
    "            process_edges(existing_edges, new_edges, existing_nodes)\n",
    "            start_idx = (edge_page - 1) * batch_size\n",
    "            end_idx = start_idx + len(new_edges) - 1\n",
    "            print(f\"Edges {start_idx}-{end_idx} retrieved.\")\n",
    "            edge_page += 1\n",
    "            save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        save_cache(existing_nodes, existing_edges, node_page, edge_page)\n",
    "        raise\n",
    "\n",
    "    return existing_nodes, existing_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes, edges = fetch_and_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object(nodes, edges):\n",
    "    sorted_nodes = sorted(nodes, key=lambda node: node['orig_id'])\n",
    "    sorted_edges = sorted(edges, key=lambda edge: edge['orig_id'])\n",
    "\n",
    "    node_features = []\n",
    "    node_labels = []\n",
    "    node_id_map = {}\n",
    "\n",
    "    for idx, node in enumerate(sorted_nodes):\n",
    "        node_id_map[node['id']] = idx\n",
    "        node_features.append(node['x'])\n",
    "        node_labels.append(node['y'])\n",
    "\n",
    "    node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "    node_labels = torch.tensor(node_labels, dtype=torch.long)\n",
    "\n",
    "    edge_index = []\n",
    "    for edge in sorted_edges:\n",
    "        if edge['src'] in node_id_map and edge['dst'] in node_id_map:\n",
    "            src = node_id_map[edge['src']]\n",
    "            dst = node_id_map[edge['dst']]\n",
    "            edge_index.append([src, dst])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    return Data(x=node_features, edge_index=edge_index, y=node_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_object(nodes, edges)\n",
    "data.train_mask = data_lib.train_mask.clone()\n",
    "data.test_mask = data_lib.test_mask.clone()\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "        self.num_hops = sum(1 for layer in self.children() if isinstance(layer, GCNConv)) + 1\n",
    "        self.optimizer = None\n",
    "        self.loss_fn = None\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "    def compile(self, optimizer, loss_fn, class_weights=None):\n",
    "        self.optimizer = optimizer\n",
    "        if class_weights is not None:\n",
    "            class_weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(next(self.parameters()).device)\n",
    "            self.loss_fn = loss_fn(weight=class_weights_tensor)\n",
    "        else:\n",
    "            self.loss_fn = loss_fn()\n",
    "\n",
    "    def fit(self, data, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            self.train()\n",
    "            self.optimizer.zero_grad()\n",
    "            out = self(data)\n",
    "            loss = self.loss_fn(out[data.train_mask], data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                acc = self.evaluate(data)\n",
    "                print(f'Epoch {epoch}, Loss: {loss:.4f}, Test Accuracy: {acc:.4f}')\n",
    "\n",
    "    def predict(self, data, node_idx=None):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            if node_idx is not None:\n",
    "                subset, edge_index, mapping, _ = k_hop_subgraph(node_idx, self.num_hops, data.edge_index, relabel_nodes=True)\n",
    "                sub_data = Data(x=data.x[subset], edge_index=edge_index)\n",
    "            else:\n",
    "                sub_data = data\n",
    "            out = self(sub_data)\n",
    "            probabilities = F.softmax(out, dim=1)\n",
    "            predictions = probabilities.argmax(dim=1)\n",
    "            if node_idx is not None:\n",
    "                return predictions[mapping.item()], probabilities[mapping.item()]\n",
    "            else:\n",
    "                return predictions, probabilities\n",
    "\n",
    "    def evaluate(self, data):\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            out = self(data)\n",
    "            pred = out.argmax(dim=1)\n",
    "            correct = pred[data.test_mask] == data.y[data.test_mask]\n",
    "            acc = int(correct.sum()) / int(data.test_mask.sum())\n",
    "            return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.tensor([[0, 1, 2, 3, 3, 5],\n",
    "                           [4, 2, 2, 2, 2, 2]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset, edge_index, _, _ = k_hop_subgraph(0, 2, data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 165])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x[subset].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data = Data(x=data.x[subset], edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset, edge_index, _, _ = k_hop_subgraph(0, 2, data.edge_index, relabel_nodes=True)\n",
    "sub_data = Data(x=data.x[subset], edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [2, 0]], device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  4, 281, 282, 304], device='cuda:0'),\n",
       " tensor([[1, 3, 1, 3, 2],\n",
       "         [2, 2, 0, 1, 0]], device='cuda:0'),\n",
       " tensor([0], device='cuda:0'),\n",
       " tensor([False, False, False,  ..., False, False, False], device='cuda:0'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_hop_subgraph(4, 2, data.edge_index, relabel_nodes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN(in_channels=data.x.shape[1], hidden_channels=100, out_channels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = [0.3, 0.7]\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=5e-4)\n",
    "model.compile(optimizer, torch.nn.CrossEntropyLoss, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3002, Test Accuracy: 0.5040\n"
     ]
    }
   ],
   "source": [
    "model.fit(data, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0'), tensor([0.6453, 0.3547], device='cuda:0'))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')\n",
      "tensor([[0.8257, 0.1743],\n",
      "        [0.8332, 0.1668],\n",
      "        [0.5656, 0.4344],\n",
      "        ...,\n",
      "        [0.6775, 0.3225],\n",
      "        [0.6726, 0.3274],\n",
      "        [0.5105, 0.4895]], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([[0.5656, 0.4344],\n",
      "        [0.8038, 0.1962],\n",
      "        [0.8054, 0.1946],\n",
      "        [0.6033, 0.3967]], device='cuda:0')\n",
      "tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predict for all nodes\n",
    "predictions_all, probabilities_all = model.predict(data)\n",
    "print(predictions_all)\n",
    "print(probabilities_all)\n",
    "\n",
    "# Predict for node with index 0\n",
    "predictions_node_0, probabilities_node_0, mapping_node_0 = model.predict(data, node_idx=2)\n",
    "print(predictions_node_0)\n",
    "print(probabilities_node_0)\n",
    "print(mapping_node_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_node_0.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor([0, 0, 0,  ..., 0, 0, 1], device='cuda:0'),\n",
    " tensor([[0.8298, 0.1702],\n",
    "         [0.8592, 0.1408],\n",
    "         [0.6100, 0.3900],\n",
    "         ...,\n",
    "         [0.5784, 0.4216],\n",
    "         [0.6302, 0.3698],\n",
    "         [0.4238, 0.5762]], device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor([0, 0, 0], device='cuda:0'),\n",
    " tensor([[0.8442, 0.1558],\n",
    "         [0.7852, 0.2148],\n",
    "         [0.8122, 0.1878]], device='cuda:0'),\n",
    " tensor([0], device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor([0, 0, 0,  ..., 1, 0, 1], device='cuda:0'),\n",
    " tensor([[0.8067, 0.1933],\n",
    "         [0.8420, 0.1580],\n",
    "         [0.6114, 0.3886],\n",
    "         ...,\n",
    "         [0.4606, 0.5394],\n",
    "         [0.6813, 0.3187],\n",
    "         [0.3630, 0.6370]], device='cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tensor([0, 0], device='cuda:0'),\n",
    " tensor([[0.9275, 0.0725],\n",
    "         [0.8699, 0.1301]], device='cuda:0'),\n",
    " tensor([0], device='cuda:0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
